{"cells":[{"metadata":{},"cell_type":"markdown","source":"**[Feature Engineering Home Page](https://www.kaggle.com/learn/feature-engineering)**\n\n---\n"},{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\nIn this exercise, you will develop a baseline model for predicting if a customer will buy an app after clicking on an ad. With this baseline model, you'll be able to see how your feature engineering and selection efforts improve the model's performance."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set up code checking\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.feature_engineering.ex1 import *\n\nimport pandas as pd\n\nclick_data = pd.read_csv('../input/feature-engineering-data/train_sample.csv',\n                         parse_dates=['click_time'])\nclick_data.head(10)","execution_count":1,"outputs":[{"output_type":"execute_result","execution_count":1,"data":{"text/plain":"       ip  app  device  os  channel          click_time      attributed_time  \\\n0   89489    3       1  13      379 2017-11-06 15:13:23                  NaN   \n1  204158   35       1  13       21 2017-11-06 15:41:07  2017-11-07 08:17:19   \n2    3437    6       1  13      459 2017-11-06 15:42:32                  NaN   \n3  167543    3       1  13      379 2017-11-06 15:56:17                  NaN   \n4  147509    3       1  13      379 2017-11-06 15:57:01                  NaN   \n5   71421   15       1  13      153 2017-11-06 16:00:00                  NaN   \n6   76953   14       1  13      379 2017-11-06 16:00:01                  NaN   \n7  187909    2       1  25      477 2017-11-06 16:00:01                  NaN   \n8  116779    1       1   8      150 2017-11-06 16:00:01                  NaN   \n9   47857    3       1  15      205 2017-11-06 16:00:01                  NaN   \n\n   is_attributed  \n0              0  \n1              1  \n2              0  \n3              0  \n4              0  \n5              0  \n6              0  \n7              0  \n8              0  \n9              0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ip</th>\n      <th>app</th>\n      <th>device</th>\n      <th>os</th>\n      <th>channel</th>\n      <th>click_time</th>\n      <th>attributed_time</th>\n      <th>is_attributed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>89489</td>\n      <td>3</td>\n      <td>1</td>\n      <td>13</td>\n      <td>379</td>\n      <td>2017-11-06 15:13:23</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>204158</td>\n      <td>35</td>\n      <td>1</td>\n      <td>13</td>\n      <td>21</td>\n      <td>2017-11-06 15:41:07</td>\n      <td>2017-11-07 08:17:19</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>3437</td>\n      <td>6</td>\n      <td>1</td>\n      <td>13</td>\n      <td>459</td>\n      <td>2017-11-06 15:42:32</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>167543</td>\n      <td>3</td>\n      <td>1</td>\n      <td>13</td>\n      <td>379</td>\n      <td>2017-11-06 15:56:17</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>147509</td>\n      <td>3</td>\n      <td>1</td>\n      <td>13</td>\n      <td>379</td>\n      <td>2017-11-06 15:57:01</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>71421</td>\n      <td>15</td>\n      <td>1</td>\n      <td>13</td>\n      <td>153</td>\n      <td>2017-11-06 16:00:00</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>76953</td>\n      <td>14</td>\n      <td>1</td>\n      <td>13</td>\n      <td>379</td>\n      <td>2017-11-06 16:00:01</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>187909</td>\n      <td>2</td>\n      <td>1</td>\n      <td>25</td>\n      <td>477</td>\n      <td>2017-11-06 16:00:01</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>116779</td>\n      <td>1</td>\n      <td>1</td>\n      <td>8</td>\n      <td>150</td>\n      <td>2017-11-06 16:00:01</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>47857</td>\n      <td>3</td>\n      <td>1</td>\n      <td>15</td>\n      <td>205</td>\n      <td>2017-11-06 16:00:01</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Baseline Model\n\nThe first thing you need to do is construct a baseline model. All new features, processing, encodings, and feature selection should improve upon this baseline model. First you need to do a bit of feature engineering before training the model itself.\n\n### 1) Features from timestamps\nFrom the timestamps, create features for the day, hour, minute and second. Store these as new integer columns `day`, `hour`, `minute`, and `second` in a new DataFrame `clicks`."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add new columns for timestamp features day, hour, minute, and second\nclicks = click_data.copy()\nclicks['day'] = clicks['click_time'].dt.day.astype('uint8')\n# Fill in the rest\nclicks['hour'] = clicks['click_time'].dt.hour.astype('uint8')\nclicks['minute'] = clicks['click_time'].dt.minute.astype('uint8')\nclicks['second'] = clicks['click_time'].dt.second.astype('uint8')\n\n# Check your answer\nq_1.check()","execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.5, \"interactionType\": 1, \"questionType\": 1, \"learnTutorialId\": 270, \"questionId\": \"1_TimestampFeatures\", \"learnToolsVersion\": \"0.3.2\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Uncomment these if you need guidance\nq_1.hint()\nq_1.solution()","execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 2, \"questionType\": 1, \"learnTutorialId\": 270, \"questionId\": \"1_TimestampFeatures\", \"learnToolsVersion\": \"0.3.2\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Hint: With a timestamp column in a dataframe, you can get access to datetime attibutes and functions with the `.dt` attribute. For example `tscolumn.dt.day` will convert a timestamp column to days","text/markdown":"<span style=\"color:#3366cc\">Hint:</span> With a timestamp column in a dataframe, you can get access to datetime attibutes and functions with the `.dt` attribute. For example `tscolumn.dt.day` will convert a timestamp column to days"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 1, \"learnTutorialId\": 270, \"questionId\": \"1_TimestampFeatures\", \"learnToolsVersion\": \"0.3.2\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Solution: \n```python\n\n    # Split up the times\n    click_times = click_data['click_time']\n    clicks['day'] = click_times.dt.day.astype('uint8')\n    clicks['hour'] = click_times.dt.hour.astype('uint8')\n    clicks['minute'] = click_times.dt.minute.astype('uint8')\n    clicks['second'] = click_times.dt.second.astype('uint8')\n    \n```","text/markdown":"<span style=\"color:#33cc99\">Solution:</span> \n```python\n\n    # Split up the times\n    click_times = click_data['click_time']\n    clicks['day'] = click_times.dt.day.astype('uint8')\n    clicks['hour'] = click_times.dt.hour.astype('uint8')\n    clicks['minute'] = click_times.dt.minute.astype('uint8')\n    clicks['second'] = click_times.dt.second.astype('uint8')\n    \n```"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### 2) Label Encoding\nFor each of the categorical features `['ip', 'app', 'device', 'os', 'channel']`, use scikit-learn's `LabelEncoder` to create new features in the `clicks` DataFrame. The new column names should be the original column name with `'_labels'` appended, like `ip_labels`."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\n\ncat_features = ['ip', 'app', 'device', 'os', 'channel']\n\n# Create new columns in clicks using preprocessing.LabelEncoder()\nlabel_encoder = preprocessing.LabelEncoder()\nfor feature in cat_features:\n    encoded = label_encoder.fit_transform(clicks[feature])\n    clicks[feature + '_labels'] = encoded\n        \n# Check your answer\nq_2.check()","execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.5, \"interactionType\": 1, \"questionType\": 1, \"learnTutorialId\": 270, \"questionId\": \"2_LabelEncoding\", \"learnToolsVersion\": \"0.3.2\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Correct","text/markdown":"<span style=\"color:#33cc33\">Correct</span>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Uncomment these if you need guidance\nq_2.hint()\nq_2.solution()","execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 2, \"questionType\": 1, \"learnTutorialId\": 270, \"questionId\": \"2_LabelEncoding\", \"learnToolsVersion\": \"0.3.2\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Hint: Try looping through each of the categorical features and using the  using LabelEncoder's .fit_transform method","text/markdown":"<span style=\"color:#3366cc\">Hint:</span> Try looping through each of the categorical features and using the  using LabelEncoder's .fit_transform method"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 1, \"learnTutorialId\": 270, \"questionId\": \"2_LabelEncoding\", \"learnToolsVersion\": \"0.3.2\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Solution: \n```python\n\n    label_encoder = preprocessing.LabelEncoder()\n    for feature in cat_features:\n        encoded = label_encoder.fit_transform(clicks[feature])\n        clicks[feature + '_labels'] = encoded\n    \n```","text/markdown":"<span style=\"color:#33cc99\">Solution:</span> \n```python\n\n    label_encoder = preprocessing.LabelEncoder()\n    for feature in cat_features:\n        encoded = label_encoder.fit_transform(clicks[feature])\n        clicks[feature + '_labels'] = encoded\n    \n```"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"clicks.head()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"       ip  app  device  os  channel          click_time      attributed_time  \\\n0   89489    3       1  13      379 2017-11-06 15:13:23                  NaN   \n1  204158   35       1  13       21 2017-11-06 15:41:07  2017-11-07 08:17:19   \n2    3437    6       1  13      459 2017-11-06 15:42:32                  NaN   \n3  167543    3       1  13      379 2017-11-06 15:56:17                  NaN   \n4  147509    3       1  13      379 2017-11-06 15:57:01                  NaN   \n\n   is_attributed  day  hour  minute  second  ip_labels  app_labels  \\\n0              0    6    15      13      23      27226           3   \n1              1    6    15      41       7     110007          35   \n2              0    6    15      42      32       1047           6   \n3              0    6    15      56      17      76270           3   \n4              0    6    15      57       1      57862           3   \n\n   device_labels  os_labels  channel_labels  \n0              1         13             120  \n1              1         13              10  \n2              1         13             157  \n3              1         13             120  \n4              1         13             120  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ip</th>\n      <th>app</th>\n      <th>device</th>\n      <th>os</th>\n      <th>channel</th>\n      <th>click_time</th>\n      <th>attributed_time</th>\n      <th>is_attributed</th>\n      <th>day</th>\n      <th>hour</th>\n      <th>minute</th>\n      <th>second</th>\n      <th>ip_labels</th>\n      <th>app_labels</th>\n      <th>device_labels</th>\n      <th>os_labels</th>\n      <th>channel_labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>89489</td>\n      <td>3</td>\n      <td>1</td>\n      <td>13</td>\n      <td>379</td>\n      <td>2017-11-06 15:13:23</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>6</td>\n      <td>15</td>\n      <td>13</td>\n      <td>23</td>\n      <td>27226</td>\n      <td>3</td>\n      <td>1</td>\n      <td>13</td>\n      <td>120</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>204158</td>\n      <td>35</td>\n      <td>1</td>\n      <td>13</td>\n      <td>21</td>\n      <td>2017-11-06 15:41:07</td>\n      <td>2017-11-07 08:17:19</td>\n      <td>1</td>\n      <td>6</td>\n      <td>15</td>\n      <td>41</td>\n      <td>7</td>\n      <td>110007</td>\n      <td>35</td>\n      <td>1</td>\n      <td>13</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>3437</td>\n      <td>6</td>\n      <td>1</td>\n      <td>13</td>\n      <td>459</td>\n      <td>2017-11-06 15:42:32</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>6</td>\n      <td>15</td>\n      <td>42</td>\n      <td>32</td>\n      <td>1047</td>\n      <td>6</td>\n      <td>1</td>\n      <td>13</td>\n      <td>157</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>167543</td>\n      <td>3</td>\n      <td>1</td>\n      <td>13</td>\n      <td>379</td>\n      <td>2017-11-06 15:56:17</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>6</td>\n      <td>15</td>\n      <td>56</td>\n      <td>17</td>\n      <td>76270</td>\n      <td>3</td>\n      <td>1</td>\n      <td>13</td>\n      <td>120</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>147509</td>\n      <td>3</td>\n      <td>1</td>\n      <td>13</td>\n      <td>379</td>\n      <td>2017-11-06 15:57:01</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>6</td>\n      <td>15</td>\n      <td>57</td>\n      <td>1</td>\n      <td>57862</td>\n      <td>3</td>\n      <td>1</td>\n      <td>13</td>\n      <td>120</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### 3) One-hot Encoding\n\nNow you have label encoded features, does it make sense to use one-hot encoding for the categorical variables ip, app, device, os, or channel?\n\nRun the following line after you've decided your answer."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check your answer (Run this code cell to receive credit!)\nq_3.solution()","execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 4, \"learnTutorialId\": 270, \"questionId\": \"3_OnehotEncoding\", \"learnToolsVersion\": \"0.3.2\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Solution: \n    The `ip` column has 58,000 values, which means it will create an extremely \n    sparse matrix with 58,000 columns. This many columns will make your model run\n    very slow, so in general you want to avoid one-hot encoding features with many\n    levels. LightGBM models work with label encoded features, so you don't actually need to \n    one-hot encode the categorical features.\n\n    ","text/markdown":"<span style=\"color:#33cc99\">Solution:</span> \n    The `ip` column has 58,000 values, which means it will create an extremely \n    sparse matrix with 58,000 columns. This many columns will make your model run\n    very slow, so in general you want to avoid one-hot encoding features with many\n    levels. LightGBM models work with label encoded features, so you don't actually need to \n    one-hot encode the categorical features.\n\n    "},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Train, validation, and test sets\nWith our baseline features ready, we need to split our data into training and validation sets. We should also hold out a test set to measure the final accuracy of the model.\n\n### 4) Train/test splits with time series data\nThis is time series data. Are they any special considerations when creating train/test splits for time series? If so, what and why?\n\nUncomment the following line after you've decided your answer."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check your answer (Run this code cell to receive credit!)\nq_4.solution()","execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Javascript object>","application/javascript":"parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 3, \"questionType\": 4, \"learnTutorialId\": 270, \"questionId\": \"4_TrainTestSplits\", \"learnToolsVersion\": \"0.3.2\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Solution: \n    Since our model is meant to predict events in the future, we must also validate the\n    model on events in the future. If the data is mixed up between the training and test \n    sets, then future data will leak in to the model and our validation results will \n    overestimate the performance on new data.\n    ","text/markdown":"<span style=\"color:#33cc99\">Solution:</span> \n    Since our model is meant to predict events in the future, we must also validate the\n    model on events in the future. If the data is mixed up between the training and test \n    sets, then future data will leak in to the model and our validation results will \n    overestimate the performance on new data.\n    "},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Create train/validation/test splits\n\nHere we'll create training, validation, and test splits. First, `clicks` DataFrame is sorted in order of increasing time. The first 80% of the rows are the train set, the next 10% are the validation set, and the last 10% are the test set."},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_cols = ['day', 'hour', 'minute', 'second', \n                'ip_labels', 'app_labels', 'device_labels',\n                'os_labels', 'channel_labels']\n\nvalid_fraction = 0.1\nclicks_srt = clicks.sort_values('click_time')\nvalid_rows = int(len(clicks_srt) * valid_fraction)\ntrain = clicks_srt[:-valid_rows * 2]\n# valid size == test size, last two sections of the data\nvalid = clicks_srt[-valid_rows * 2:-valid_rows]\ntest = clicks_srt[-valid_rows:]","execution_count":13,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train with LightGBM\n\nNow we can create LightGBM dataset objects for each of the smaller datasets and train the baseline model."},{"metadata":{"_kg_hide-output":true,"trusted":true,"collapsed":true},"cell_type":"code","source":"import lightgbm as lgb\n\ndtrain = lgb.Dataset(train[feature_cols], label=train['is_attributed'])\ndvalid = lgb.Dataset(valid[feature_cols], label=valid['is_attributed'])\ndtest = lgb.Dataset(test[feature_cols], label=test['is_attributed'])\n\nparam = {'num_leaves': 64, 'objective': 'binary'}\nparam['metric'] = 'auc'\nnum_round = 1000\nbst = lgb.train(param, dtrain, num_round, valid_sets=[dvalid], early_stopping_rounds=10)","execution_count":14,"outputs":[{"output_type":"stream","text":"[1]\tvalid_0's auc: 0.947734\nTraining until validation scores don't improve for 10 rounds.\n[2]\tvalid_0's auc: 0.947954\n[3]\tvalid_0's auc: 0.948279\n[4]\tvalid_0's auc: 0.948733\n[5]\tvalid_0's auc: 0.948769\n[6]\tvalid_0's auc: 0.949025\n[7]\tvalid_0's auc: 0.949396\n[8]\tvalid_0's auc: 0.949249\n[9]\tvalid_0's auc: 0.949374\n[10]\tvalid_0's auc: 0.949571\n[11]\tvalid_0's auc: 0.949599\n[12]\tvalid_0's auc: 0.949297\n[13]\tvalid_0's auc: 0.949485\n[14]\tvalid_0's auc: 0.949501\n[15]\tvalid_0's auc: 0.949903\n[16]\tvalid_0's auc: 0.949962\n[17]\tvalid_0's auc: 0.950057\n[18]\tvalid_0's auc: 0.950094\n[19]\tvalid_0's auc: 0.950113\n[20]\tvalid_0's auc: 0.950315\n[21]\tvalid_0's auc: 0.950373\n[22]\tvalid_0's auc: 0.950552\n[23]\tvalid_0's auc: 0.950456\n[24]\tvalid_0's auc: 0.950437\n[25]\tvalid_0's auc: 0.95057\n[26]\tvalid_0's auc: 0.950658\n[27]\tvalid_0's auc: 0.950605\n[28]\tvalid_0's auc: 0.951064\n[29]\tvalid_0's auc: 0.951003\n[30]\tvalid_0's auc: 0.950978\n[31]\tvalid_0's auc: 0.951012\n[32]\tvalid_0's auc: 0.951134\n[33]\tvalid_0's auc: 0.951197\n[34]\tvalid_0's auc: 0.951257\n[35]\tvalid_0's auc: 0.951407\n[36]\tvalid_0's auc: 0.951455\n[37]\tvalid_0's auc: 0.951457\n[38]\tvalid_0's auc: 0.951474\n[39]\tvalid_0's auc: 0.951514\n[40]\tvalid_0's auc: 0.951583\n[41]\tvalid_0's auc: 0.951753\n[42]\tvalid_0's auc: 0.951747\n[43]\tvalid_0's auc: 0.951819\n[44]\tvalid_0's auc: 0.951925\n[45]\tvalid_0's auc: 0.951963\n[46]\tvalid_0's auc: 0.951942\n[47]\tvalid_0's auc: 0.952037\n[48]\tvalid_0's auc: 0.952109\n[49]\tvalid_0's auc: 0.95219\n[50]\tvalid_0's auc: 0.952296\n[51]\tvalid_0's auc: 0.952332\n[52]\tvalid_0's auc: 0.952343\n[53]\tvalid_0's auc: 0.952373\n[54]\tvalid_0's auc: 0.952421\n[55]\tvalid_0's auc: 0.952444\n[56]\tvalid_0's auc: 0.952478\n[57]\tvalid_0's auc: 0.952557\n[58]\tvalid_0's auc: 0.952634\n[59]\tvalid_0's auc: 0.952673\n[60]\tvalid_0's auc: 0.952702\n[61]\tvalid_0's auc: 0.952788\n[62]\tvalid_0's auc: 0.952792\n[63]\tvalid_0's auc: 0.952822\n[64]\tvalid_0's auc: 0.95287\n[65]\tvalid_0's auc: 0.952899\n[66]\tvalid_0's auc: 0.952913\n[67]\tvalid_0's auc: 0.952917\n[68]\tvalid_0's auc: 0.952929\n[69]\tvalid_0's auc: 0.952928\n[70]\tvalid_0's auc: 0.952927\n[71]\tvalid_0's auc: 0.952961\n[72]\tvalid_0's auc: 0.953009\n[73]\tvalid_0's auc: 0.953068\n[74]\tvalid_0's auc: 0.953096\n[75]\tvalid_0's auc: 0.953119\n[76]\tvalid_0's auc: 0.953113\n[77]\tvalid_0's auc: 0.953131\n[78]\tvalid_0's auc: 0.953169\n[79]\tvalid_0's auc: 0.953202\n[80]\tvalid_0's auc: 0.953197\n[81]\tvalid_0's auc: 0.953203\n[82]\tvalid_0's auc: 0.953247\n[83]\tvalid_0's auc: 0.953248\n[84]\tvalid_0's auc: 0.953267\n[85]\tvalid_0's auc: 0.953267\n[86]\tvalid_0's auc: 0.953298\n[87]\tvalid_0's auc: 0.953281\n[88]\tvalid_0's auc: 0.953296\n[89]\tvalid_0's auc: 0.953338\n[90]\tvalid_0's auc: 0.95331\n[91]\tvalid_0's auc: 0.953331\n[92]\tvalid_0's auc: 0.953346\n[93]\tvalid_0's auc: 0.953328\n[94]\tvalid_0's auc: 0.953332\n[95]\tvalid_0's auc: 0.953351\n[96]\tvalid_0's auc: 0.953344\n[97]\tvalid_0's auc: 0.953357\n[98]\tvalid_0's auc: 0.953375\n[99]\tvalid_0's auc: 0.953369\n[100]\tvalid_0's auc: 0.953375\n[101]\tvalid_0's auc: 0.953374\n[102]\tvalid_0's auc: 0.953376\n[103]\tvalid_0's auc: 0.953407\n[104]\tvalid_0's auc: 0.953416\n[105]\tvalid_0's auc: 0.953413\n[106]\tvalid_0's auc: 0.953417\n[107]\tvalid_0's auc: 0.953416\n[108]\tvalid_0's auc: 0.95338\n[109]\tvalid_0's auc: 0.953382\n[110]\tvalid_0's auc: 0.953388\n[111]\tvalid_0's auc: 0.953385\n[112]\tvalid_0's auc: 0.953385\n[113]\tvalid_0's auc: 0.953387\n[114]\tvalid_0's auc: 0.953395\n[115]\tvalid_0's auc: 0.953402\n[116]\tvalid_0's auc: 0.9534\nEarly stopping, best iteration is:\n[106]\tvalid_0's auc: 0.953417\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Evaluate the model\nFinally, with the model trained, I'll evaluate it's performance on the test set. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\n\nypred = bst.predict(test[feature_cols])\nscore = metrics.roc_auc_score(test['is_attributed'], ypred)\nprint(f\"Test score: {score}\")","execution_count":15,"outputs":[{"output_type":"stream","text":"Test score: 0.9645033391617757\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"This will be our baseline score for the model. When we transform features, add new ones, or perform feature selection, we should be improving on this score. However, since this is the test set, we only want to look at it at the end of all our manipulations. At the very end of this course you'll look at the test score again to see if you improved on the baseline model.\n\n# Keep Going\nNow that you have a baseline model, you are ready to learn **[Categorical Encoding Techniques](https://www.kaggle.com/matleonard/categorical-encodings)** to improve it."},{"metadata":{},"cell_type":"markdown","source":"---\n**[Feature Engineering Home Page](https://www.kaggle.com/learn/feature-engineering)**\n\n\n\n\n\n*Have questions or comments? Visit the [Learn Discussion forum](https://www.kaggle.com/learn-forum) to chat with other Learners.*"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":4}